{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Señas Chapinas: Traductor de LENSEGUA**\n",
    "#### *Módulo de Procesamiento de Lenguaje Natural*\n",
    "\n",
    "Stefano Alberto Aragoni Maldonado"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------------\n",
    "\n",
    "#### **Generación de Interpretaciones**\n",
    "\n",
    "En este programa se busca poder interpretar las 200 frases del conjunto de validación. En realidad, se generarán las interpretaciones utilizando dos modelos diferentes; el modelo GPT-3.5-Turbo base y el modelo GPT-3.5-Turbo fine-tuneado para la tarea de interpretación de LENSEGUA. \n",
    "\n",
    "Además, por cada modelo se generarán cinco posibles interpretaciones para cada frase. Esto debido a que cada interpretación utilizará un prompt diferente.\n",
    "\n",
    "Por lo tanto, ya que son 200 frases, 2 modelos, y 5 prompts, se generarán 2,000 interpretaciones en total."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "\n",
    "#### *Importar librerías*\n",
    "Como primer paso, se importan las librerías necesarias para el desarrollo del problema."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import csv\n",
    "import re\n",
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "\n",
    "#### *Cargar el dataset*\n",
    "\n",
    "Luego, se carga el dataset que contiene las frases en español y su contraparte en LENSEGUA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LENSEGUA</th>\n",
       "      <th>ESPAÑOL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Hoy estudiantes ocupados mucho</td>\n",
       "      <td>Hoy los estudiantes están muy ocupados.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Tu trabajar dónde pregunta</td>\n",
       "      <td>¿Dónde trabajas?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ojalá hoy carro mucho no</td>\n",
       "      <td>Espero que hoy no haya tráfico.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Haber carro mucho</td>\n",
       "      <td>Hay tráfico.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Pasado yo tarde llegar porque carro mucho</td>\n",
       "      <td>Llegué tarde porque había tráfico.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    LENSEGUA  \\\n",
       "0             Hoy estudiantes ocupados mucho   \n",
       "1                 Tu trabajar dónde pregunta   \n",
       "2                   Ojalá hoy carro mucho no   \n",
       "3                          Haber carro mucho   \n",
       "4  Pasado yo tarde llegar porque carro mucho   \n",
       "\n",
       "                                   ESPAÑOL  \n",
       "0  Hoy los estudiantes están muy ocupados.  \n",
       "1                         ¿Dónde trabajas?  \n",
       "2          Espero que hoy no haya tráfico.  \n",
       "3                             Hay tráfico.  \n",
       "4       Llegué tarde porque había tráfico.  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"../../dataset/processed/validation_data.csv\")   # Load the dataset\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "\n",
    "#### *Definición de prompts*\n",
    "\n",
    "Posteriormente, se definen los prompts que se utilizarán para generar las interpretaciones de las frases en LENSEGUA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_v0 = 'Eres un intérprete experto en Lengua de Señas de Guatemala (LENSEGUA). El usuario te proporcionará frases en español escritas utilizando la gramática de LENSEGUA. Tu tarea es interpretarlas y convertirlas en español gramaticalmente correcto.'\n",
    "\n",
    "prompt_v1 = 'Soy un intérprete experto en Lengua de Señas de Guatemala (LENSEGUA). El usuario me proporcionará frases en español escritas utilizando la gramática de LENSEGUA. Mi tarea es interpretarlas y convertirlas en español gramaticalmente correcto.'\n",
    "\n",
    "prompt_v2 = 'Eres un intérprete experto en Lengua de Señas de Guatemala (LENSEGUA). El usuario te proporcionará frases en español escritas utilizando la gramática de LENSEGUA. Tu tarea es interpretarlas y convertirlas en español gramaticalmente correcto, teniendo en cuenta la siguiente regla específica: Las palabras “pasado”, “futuro” y “antes” indican la conjugación verbal. Debes conjugar correctamente los verbos en tu respuesta sin incluir las palabras “pasado”, “futuro” o “antes”.'\n",
    "\n",
    "prompt_v3 = 'Eres un intérprete experto en Lengua de Señas de Guatemala (LENSEGUA). El usuario te proporcionará frases en español escritas utilizando la gramática de LENSEGUA. Tu tarea es interpretarlas y convertirlas en español gramaticalmente correcto, teniendo en cuenta las siguientes reglas específicas: 1. No debes interpretar las frases como preguntas, ni agregar una entonación interrogativa, a menos que incluyan las palabras \"pregunta\" o \"sí o no\". 2. Las palabras “pasado”, “futuro” y “antes” indican la conjugación verbal. Debes conjugar correctamente los verbos en tu respuesta sin incluir las palabras “pasado”, “futuro” o “antes”. 3. La frase “carro mucho” debe interpretarse como “tráfico”. 4. La frase “bien mucho” debe interpretarse como “muy bien”.'\n",
    "\n",
    "prompt_v4 = 'Eres un intérprete experto en Lengua de Señas de Guatemala (LENSEGUA). El usuario te proporcionará frases en español escritas utilizando la gramática de LENSEGUA. Tu tarea es interpretarlas y convertirlas en español gramaticalmente correcto, teniendo en cuenta las siguientes reglas específicas: 1. No debes interpretar las frases como preguntas, ni agregar una entonación interrogativa, a menos que incluyan las palabras \"pregunta\" o \"sí o no\". 2. Las palabras “pasado”, “futuro” y “antes” indican la conjugación verbal. Debes conjugar correctamente los verbos en tu respuesta sin incluir las palabras “pasado”, “futuro” o “antes”. 3. La frase “carro mucho” debe interpretarse como “tráfico”. 4. La frase “bien mucho” debe interpretarse como “muy bien”. 5. Mantén el orden de los elementos de la interpretación final lo más similar posible al texto original cuando sea gramaticalmente válido en español. Por ejemplo, si la frase en LENSEGUA es \"Por favor cuando tu salir luz apagar\", la interpretación debe ser \"Por favor cuando salgas apaga la luz\" en lugar de \"Por favor apaga la luz cuando salgas\".'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "\n",
    "#### *Definición de modelos*\n",
    "\n",
    "Asimismo, se definen los modelos que se utilizarán para generar las interpretaciones de las frases en LENSEGUA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_finetuned = \"ft:gpt-3.5-turbo-0125:personal:lensegua-16-02-2:9wdLYlLV:ckpt-step-262\"\n",
    "\n",
    "model_original = \"gpt-3.5-turbo-0125\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "\n",
    "#### *Función para generar interpretaciones*\n",
    "\n",
    "Con todo lo anterior, se define una función que permitirá generar las interpretaciones de las frases en LENSEGUA. Esta recibe como parámetros el dataset, el prompt y el modelo a utilizar.\n",
    "\n",
    "Como resultado, se obtiene un archivo CSV que contiene la información del dataset original y las interpretaciones generadas. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_responses(data, prompt, model, file_name, temp=1):\n",
    "\n",
    "    # OpenAI API client gets initialized with the API key\n",
    "    client = OpenAI(\n",
    "        api_key=''\n",
    "    )\n",
    "\n",
    "    # Rows for new dataset\n",
    "    rows = []\n",
    "\n",
    "    for i, row in data.iterrows():\n",
    "\n",
    "        # Get rows from the dataset\n",
    "        spanish = row[\"ESPAÑOL\"]\n",
    "        lensegua = row[\"LENSEGUA\"]\n",
    "\n",
    "        # Generate the response\n",
    "        response = client.chat.completions.create(\n",
    "            model=model,\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": prompt},\n",
    "                {\"role\": \"user\", \"content\": lensegua + \" ->\"}\n",
    "            ],\n",
    "            max_tokens=150,\n",
    "            temperature=temp,\n",
    "        )\n",
    "\n",
    "        # Get the response from the API\n",
    "        response = response.choices[0].message.content\n",
    "\n",
    "        # Remove \" from the response\n",
    "        response = response.replace('\"', '').replace('“', '').replace('”', '').replace(\"'\", '').replace(\",\", \"\").replace(\"*\", \"\").replace(\"\\n\", \"\")\n",
    "\n",
    "        # Append the rows to the new dataset\n",
    "        rows.append([spanish, lensegua, response])\n",
    "\n",
    "    # Create the new dataset\n",
    "    new_data = pd.DataFrame(rows, columns=[\"ESPAÑOL\", \"LENSEGUA\", \"RESPUESTA\"])\n",
    "\n",
    "    # Save the new dataset\n",
    "    new_data.to_csv(file_name, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get responses for the original model\n",
    "get_responses(data, prompt_v0, model_original, \"../../dataset/interpretations/original_pv0.csv\")\n",
    "\n",
    "get_responses(data, prompt_v1, model_original, \"../../dataset/interpretations/original_pv1.csv\")\n",
    "\n",
    "get_responses(data, prompt_v2, model_original, \"../../dataset/interpretations/original_pv2.csv\")\n",
    "\n",
    "get_responses(data, prompt_v3, model_original, \"../../dataset/interpretations/original_pv3.csv\")\n",
    "\n",
    "get_responses(data, prompt_v4, model_original, \"../../dataset/interpretations/original_pv4.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get responses for the fine-tuned model\n",
    "get_responses(data, prompt_v0, model_finetuned, \"../../dataset/interpretations/finetuned_pv0.csv\")\n",
    "\n",
    "get_responses(data, prompt_v1, model_finetuned, \"../../dataset/interpretations/finetuned_pv1.csv\")\n",
    "\n",
    "get_responses(data, prompt_v2, model_finetuned, \"../../dataset/interpretations/finetuned_pv2.csv\")\n",
    "\n",
    "get_responses(data, prompt_v3, model_finetuned, \"../../dataset/interpretations/finetuned_pv3.csv\")\n",
    "\n",
    "get_responses(data, prompt_v4, model_finetuned, \"../../dataset/interpretations/finetuned_pv4.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
