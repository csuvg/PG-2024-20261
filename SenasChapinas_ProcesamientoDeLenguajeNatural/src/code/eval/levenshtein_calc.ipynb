{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Señas Chapinas: Traductor de LENSEGUA**\n",
    "#### *Módulo de Procesamiento de Lenguaje Natural*\n",
    "\n",
    "Stefano Alberto Aragoni Maldonado"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------------\n",
    "\n",
    "#### **Cálculo de Distancias de Levenshtein**\n",
    "\n",
    "En este programa se busca evaluar las interpretaciones realizadas por ambos, el modelo GPT-3.5-Turbo base y el modelo GPT-3.5-Turbo fine-tuneado para la tarea de interpretación de LENSEGUA. \n",
    "\n",
    "Esto se hará a través de calcular la distancia de Levenshtein entre las interpretaciones generadas y las interpretaciones teóricas esperadas. \n",
    "\n",
    "Cabe destacar que por cada modelo se generaron cuatro posibles interpretaciones para cada frase. Esto debido a que se utilizaron 4 prompts distintos para la generación de interpretaciones."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "\n",
    "#### *Importar librerías*\n",
    "Como primer paso, se importan las librerías necesarias para el desarrollo del problema."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import csv\n",
    "import re\n",
    "import Levenshtein as lev"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "\n",
    "#### *Cargar los datasets*\n",
    "\n",
    "Luego, se carga los datasets que contienen las interpretaciones generadas por ambos modelos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_pv0 = pd.read_csv('../../dataset/interpretations/original_pv0.csv')\n",
    "original_pv1 = pd.read_csv('../../dataset/interpretations/original_pv1.csv')\n",
    "original_pv2 = pd.read_csv('../../dataset/interpretations/original_pv2.csv')\n",
    "original_pv3 = pd.read_csv('../../dataset/interpretations/original_pv3.csv')\n",
    "original_pv4 = pd.read_csv('../../dataset/interpretations/original_pv4.csv')\n",
    "\n",
    "finetuned_pv0 = pd.read_csv('../../dataset/interpretations/finetuned_pv0.csv')\n",
    "finetuned_pv1 = pd.read_csv('../../dataset/interpretations/finetuned_pv1.csv')\n",
    "finetuned_pv2 = pd.read_csv('../../dataset/interpretations/finetuned_pv2.csv')\n",
    "finetuned_pv3 = pd.read_csv('../../dataset/interpretations/finetuned_pv3.csv')\n",
    "finetuned_pv4 = pd.read_csv('../../dataset/interpretations/finetuned_pv4.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "\n",
    "#### *Función para hacer el cálculo de distancia de Levenshtein*\n",
    "\n",
    "Con todo lo anterior, se define una función que permitirá calcular la distancia de Levenshtein entre las interpretaciones generadas y las interpretaciones esperadas. Esta recibe como parámetros el dataset con las el texto ESPAÑOL (correcto), el texto LENSEGUA (frase a interpretar), y el texto RESPUESTA (interpretación generada por el modelo).\n",
    "\n",
    "Como resultado, se obtiene un archivo CSV que contiene la información del dataset original y una columna con la distancia de Levenshtein para cada interpretación generada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "def leveshtein_distance(data, file_name):\n",
    "\n",
    "    # Rows for new dataset\n",
    "    rows = []\n",
    "\n",
    "    for i, row in data.iterrows():\n",
    "\n",
    "        # Get rows from the dataset\n",
    "        spanish = row[\"ESPAÑOL\"]\n",
    "        interpreted = row[\"RESPUESTA\"]\n",
    "\n",
    "        # Calculate the levenshtein distance between spanish and interpreted\n",
    "        distance = lev.distance(spanish, interpreted)\n",
    "\n",
    "        # Calculate the percentage difference\n",
    "        max_length = max(len(spanish), len(interpreted))\n",
    "        percentage_diff = (distance / max_length) * 100\n",
    "\n",
    "        # Add the row to the new dataset\n",
    "        rows.append([spanish, interpreted, max_length, distance, percentage_diff])\n",
    "\n",
    "    # Create the new dataset\n",
    "    results_df = pd.DataFrame(rows, columns=[\"ESPAÑOL\", \"RESPUESTA\", \"MAX_LENGTH\", \"LEVENSHTEIN_DISTANCE\", \"PERCENTAGE_DIFFERENCE\"])\n",
    "\n",
    "    # Save the new dataset\n",
    "    results_df.to_csv(file_name, index=False)\n",
    "\n",
    "    # Return the mean of the levenshtein distances and the average percentage difference\n",
    "    avg_max_length = results_df[\"MAX_LENGTH\"].mean()\n",
    "    avg_distance = results_df[\"LEVENSHTEIN_DISTANCE\"].mean()\n",
    "    avg_percentage_diff = results_df[\"PERCENTAGE_DIFFERENCE\"].mean()\n",
    "\n",
    "    return avg_max_length, avg_distance, avg_percentage_diff\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Levenshtein Distance between Spanish and Interpreted Sentences\n",
      "\n",
      "Original Model - Prompt V0: \n",
      "\tAverage Sentence Length:  31.905\n",
      "\tAverage Levenshtein Distance:  10.065\n",
      "\tAverage Percentage Difference:  27.932895900120712 %\n",
      "\n",
      "Original Model - Prompt V1: \n",
      "\tAverage Sentence Length:  32.825\n",
      "\tAverage Levenshtein Distance:  10.755\n",
      "\tAverage Percentage Difference:  28.1327943786462 %\n",
      "\n",
      "Original Model - Prompt V2: \n",
      "\tAverage Sentence Length:  29.625\n",
      "\tAverage Levenshtein Distance:  8.66\n",
      "\tAverage Percentage Difference:  27.78596639438847 %\n",
      "\n",
      "Original Model - Prompt V3: \n",
      "\tAverage Sentence Length:  29.215\n",
      "\tAverage Levenshtein Distance:  8.635\n",
      "\tAverage Percentage Difference:  28.59262308454481 %\n",
      "\n",
      "Original Model - Prompt V4: \n",
      "\tAverage Sentence Length:  29.235\n",
      "\tAverage Levenshtein Distance:  8.68\n",
      "\tAverage Percentage Difference:  28.548691520694337 %\n"
     ]
    }
   ],
   "source": [
    "print(\"Levenshtein Distance between Spanish and Interpreted Sentences\")\n",
    "\n",
    "original_prompt_v0 = leveshtein_distance(original_pv0, \"../../dataset/distances/distances_original_pv0.csv\")\n",
    "print(\"\\nOriginal Model - Prompt V0: \")\n",
    "print(\"\\tAverage Sentence Length: \", original_prompt_v0[0])\n",
    "print(\"\\tAverage Levenshtein Distance: \", original_prompt_v0[1])\n",
    "print(\"\\tAverage Percentage Difference: \", original_prompt_v0[2], \"%\")\n",
    "\n",
    "original_prompt_v1 = leveshtein_distance(original_pv1, \"../../dataset/distances/distances_original_pv1.csv\")\n",
    "print(\"\\nOriginal Model - Prompt V1: \")\n",
    "print(\"\\tAverage Sentence Length: \", original_prompt_v1[0])\n",
    "print(\"\\tAverage Levenshtein Distance: \", original_prompt_v1[1])\n",
    "print(\"\\tAverage Percentage Difference: \", original_prompt_v1[2], \"%\")\n",
    "\n",
    "original_prompt_v2 = leveshtein_distance(original_pv2, \"../../dataset/distances/distances_original_pv2.csv\")\n",
    "print(\"\\nOriginal Model - Prompt V2: \")\n",
    "print(\"\\tAverage Sentence Length: \", original_prompt_v2[0])\n",
    "print(\"\\tAverage Levenshtein Distance: \", original_prompt_v2[1])\n",
    "print(\"\\tAverage Percentage Difference: \", original_prompt_v2[2], \"%\")\n",
    "\n",
    "original_prompt_v3 = leveshtein_distance(original_pv3, \"../../dataset/distances/distances_original_pv3.csv\")\n",
    "print(\"\\nOriginal Model - Prompt V3: \")\n",
    "print(\"\\tAverage Sentence Length: \", original_prompt_v3[0])\n",
    "print(\"\\tAverage Levenshtein Distance: \", original_prompt_v3[1])\n",
    "print(\"\\tAverage Percentage Difference: \", original_prompt_v3[2], \"%\")\n",
    "\n",
    "original_prompt_v4 = leveshtein_distance(original_pv4, \"../../dataset/distances/distances_original_pv4.csv\")\n",
    "print(\"\\nOriginal Model - Prompt V4: \")\n",
    "print(\"\\tAverage Sentence Length: \", original_prompt_v4[0])\n",
    "print(\"\\tAverage Levenshtein Distance: \", original_prompt_v4[1])\n",
    "print(\"\\tAverage Percentage Difference: \", original_prompt_v4[2], \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Levenshtein Distance between Spanish and Interpreted Sentences\n",
      "\n",
      "Fine-tuned Model - Prompt V0: \n",
      "\tAverage Sentence Length:  27.655\n",
      "\tAverage Levenshtein Distance:  5.815\n",
      "\tAverage Percentage Difference:  20.12713768277029 %\n",
      "\n",
      "Fine-tuned Model - Prompt V1: \n",
      "\tAverage Sentence Length:  27.925\n",
      "\tAverage Levenshtein Distance:  5.84\n",
      "\tAverage Percentage Difference:  19.098171768746294 %\n",
      "\n",
      "Fine-tuned Model - Prompt V2: \n",
      "\tAverage Sentence Length:  27.23\n",
      "\tAverage Levenshtein Distance:  5.37\n",
      "\tAverage Percentage Difference:  19.00521992929269 %\n",
      "\n",
      "Fine-tuned Model - Prompt V3: \n",
      "\tAverage Sentence Length:  27.05\n",
      "\tAverage Levenshtein Distance:  4.3\n",
      "\tAverage Percentage Difference:  15.276810080558636 %\n",
      "\n",
      "Fine-tuned Model - Prompt V4: \n",
      "\tAverage Sentence Length:  26.635\n",
      "\tAverage Levenshtein Distance:  3.375\n",
      "\tAverage Percentage Difference:  11.979230778799952 %\n"
     ]
    }
   ],
   "source": [
    "print(\"Levenshtein Distance between Spanish and Interpreted Sentences\")\n",
    "\n",
    "finetuned_prompt_v0 = leveshtein_distance(finetuned_pv0, \"../../dataset/distances/distances_finetuned_pv0.csv\")\n",
    "print(\"\\nFine-tuned Model - Prompt V0: \")\n",
    "print(\"\\tAverage Sentence Length: \", finetuned_prompt_v0[0])\n",
    "print(\"\\tAverage Levenshtein Distance: \", finetuned_prompt_v0[1])\n",
    "print(\"\\tAverage Percentage Difference: \", finetuned_prompt_v0[2], \"%\")\n",
    "\n",
    "finetuned_prompt_v1 = leveshtein_distance(finetuned_pv1, \"../../dataset/distances/distances_finetuned_pv1.csv\")\n",
    "print(\"\\nFine-tuned Model - Prompt V1: \")\n",
    "print(\"\\tAverage Sentence Length: \", finetuned_prompt_v1[0])\n",
    "print(\"\\tAverage Levenshtein Distance: \", finetuned_prompt_v1[1])\n",
    "print(\"\\tAverage Percentage Difference: \", finetuned_prompt_v1[2], \"%\")\n",
    "\n",
    "finetuned_prompt_v2 = leveshtein_distance(finetuned_pv2, \"../../dataset/distances/distances_finetuned_pv2.csv\")\n",
    "print(\"\\nFine-tuned Model - Prompt V2: \")\n",
    "print(\"\\tAverage Sentence Length: \", finetuned_prompt_v2[0])\n",
    "print(\"\\tAverage Levenshtein Distance: \", finetuned_prompt_v2[1])\n",
    "print(\"\\tAverage Percentage Difference: \", finetuned_prompt_v2[2], \"%\")\n",
    "\n",
    "finetuned_prompt_v3 = leveshtein_distance(finetuned_pv3, \"../../dataset/distances/distances_finetuned_pv3.csv\")\n",
    "print(\"\\nFine-tuned Model - Prompt V3: \")\n",
    "print(\"\\tAverage Sentence Length: \", finetuned_prompt_v3[0])\n",
    "print(\"\\tAverage Levenshtein Distance: \", finetuned_prompt_v3[1])\n",
    "print(\"\\tAverage Percentage Difference: \", finetuned_prompt_v3[2], \"%\")\n",
    "\n",
    "finetuned_prompt_v4 = leveshtein_distance(finetuned_pv4, \"../../dataset/distances/distances_finetuned_pv4.csv\")\n",
    "print(\"\\nFine-tuned Model - Prompt V4: \")\n",
    "print(\"\\tAverage Sentence Length: \", finetuned_prompt_v4[0])\n",
    "print(\"\\tAverage Levenshtein Distance: \", finetuned_prompt_v4[1])\n",
    "print(\"\\tAverage Percentage Difference: \", finetuned_prompt_v4[2], \"%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
